{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "K.set_floatx('float64')\n",
    "\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Layer, Add, Multiply, Conv1D, Conv1DTranspose\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "from tensorflow.keras.initializers import RandomUniform, Constant\n",
    "\n",
    "from tf_extensions.tf_custom.layers import MixingBlock, Snake\n",
    "from tf_extensions.tf_custom.models import GaussianBetaVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the spectral audio data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139438, 1026)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "_PATH_TO_AUDIO_DATA = \"./dance_wav/audio_spectral_data_stft.pkl\"\n",
    "spectral_audio_dataset = joblib.load(_PATH_TO_AUDIO_DATA)\n",
    "\n",
    "meta_data = spectral_audio_dataset[\"MetaInfo\"]\n",
    "SR        = meta_data[\"SampleRate\"]\n",
    "DUR       = meta_data[\"ClipDuration\"]\n",
    "OVERLAP   = meta_data[\"Overlap\"]\n",
    "NFFT      = meta_data[\"Num_fft\"]\n",
    "FFTWIN    = meta_data[\"FFTWindow\"]\n",
    "\n",
    "stft_frames = spectral_audio_dataset[\"Data\"]\n",
    "stft_frames = np.reshape(stft_frames, newshape=(-1, np.prod(stft_frames.shape[1:])))\n",
    "print(stft_frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Extract training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-108.99208378847092 106.08346116204625\n",
      "(125494, 1026) (13944, 1026)\n",
      "(125494, 1026) (13944, 1026)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "tsize = 0.1\n",
    "state = 1338\n",
    "\n",
    "scaler = StandardScaler() #MinMaxScaler(feature_range=(-1, 1))\n",
    "stft_frames_scaled = scaler.fit_transform(stft_frames)\n",
    "print(stft_frames_scaled.min(), stft_frames_scaled.max())\n",
    "\n",
    "X_train, X_test = train_test_split(\n",
    "    stft_frames_scaled, test_size=tsize, random_state=state\n",
    ")\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# Get the magnitude spectrograms\n",
    "stft_train = tf.convert_to_tensor(\n",
    "    X_train, dtype=K.floatx()\n",
    ")\n",
    "stft_test = tf.convert_to_tensor(\n",
    "    X_test,  dtype=K.floatx() \n",
    ")\n",
    "print(stft_train.shape, stft_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(Layer):\n",
    "    \n",
    "    def __init__(self, maps, kernel, alpha=1, *args, **kwargs):\n",
    "        super(ConvBlock, self).__init__(*args, **kwargs)\n",
    "        self.conv = Conv1D(maps, kernel_size=kernel, strides=2, padding=\"causal\")\n",
    "        self.acti = Snake(alpha, trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        return self.acti(x)        \n",
    "\n",
    "class TransposeConvBlock(Layer):\n",
    "    \n",
    "    def __init__(self, maps, kernel, alpha=1, *args, **kwargs):\n",
    "        super(TransposeConvBlock, self).__init__(*args, **kwargs)\n",
    "        self.conv = Conv1DTranspose(maps, kernel_size=kernel, \n",
    "                strides=2, padding=\"same\")\n",
    "        self.acti = Snake(alpha, trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        return self.acti(x)         \n",
    "        \n",
    "def make_encoder(input_dim, latent_dim):\n",
    "    # Setup the NN inputs\n",
    "    input_shape   = (np.prod(input_dim), )\n",
    "    encoder_input = Input(shape=input_shape, name=\"encoder_input\")    \n",
    "    encoder_reshaped = Reshape(input_dim)(encoder_input)\n",
    "    \n",
    "    # First Conv1D will produce a 12-channel output\n",
    "    conv_0 = Conv1D(4, kernel_size=5, strides=2, padding=\"valid\")(encoder_reshaped)\n",
    "    conv_0 = Snake()(conv_0)\n",
    "    \n",
    "    # Pass through a series of convolutions\n",
    "    conv_1 = ConvBlock( 8, kernel=3)(conv_0)\n",
    "    conv_2 = ConvBlock(12, kernel=3)(conv_1) #Conv1D(36, kernel_size=3, strides=2, padding=\"causal\", activation=\"relu\")(conv_1)\n",
    "    conv_3 = ConvBlock(16, kernel=3)(conv_2)\n",
    "    conv_4 = ConvBlock(20, kernel=3)(conv_3) #Conv1D(60, kernel_size=3, strides=2, padding=\"causal\", activation=\"relu\")(conv_3)\n",
    "    conv_5 = ConvBlock(24, kernel=3)(conv_4)\n",
    "    conv_6 = ConvBlock(28, kernel=3)(conv_5) #Conv1D(84, kernel_size=3, strides=2, padding=\"causal\", activation=\"relu\")(conv_5)\n",
    "    \n",
    "    # Flatten the data\n",
    "    flat_0 = Flatten()(conv_6)\n",
    "    \n",
    "    # Prepare the prior distribution q(z|x)\n",
    "    encoder_dense = Dense(\n",
    "        2*latent_dim, name=\"encoder\",\n",
    "        kernel_initializer=\"zeros\", bias_initializer='zeros'\n",
    "    )(flat_0)\n",
    "    \n",
    "    return Model(inputs=[encoder_input], outputs=[encoder_dense], name=\"encoder\")\n",
    "\n",
    "def make_decoder(input_dim, latent_dim):\n",
    "    # Setup the NN Input\n",
    "    decoder_input = Input(shape=(latent_dim, ), name=\"decoder_input\")\n",
    "    \n",
    "    # Use a dense layer to restructure the data\n",
    "    decoder_reshaped = Dense(112)(decoder_input)\n",
    "    decoder_reshaped = Snake()(decoder_reshaped)\n",
    "    decoder_reshaped = Reshape((4, 28))(decoder_reshaped)\n",
    "    \n",
    "    # Pass through a series of convolutions\n",
    "    conv_0 = TransposeConvBlock(24, kernel=3)(decoder_reshaped)\n",
    "    conv_1 = TransposeConvBlock(20, kernel=3)(conv_0)\n",
    "    conv_2 = TransposeConvBlock(16, kernel=3)(conv_1)\n",
    "    conv_3 = TransposeConvBlock(12, kernel=3)(conv_2)\n",
    "    conv_4 = TransposeConvBlock(8, kernel=3)(conv_3)\n",
    "    conv_5 = TransposeConvBlock(4, kernel=3)(conv_4)\n",
    "    conv_6 = TransposeConvBlock(2, kernel=3)(conv_5)\n",
    "    \n",
    "    flat_0 = Flatten()(conv_6)\n",
    "    \n",
    "    input_shape = np.prod(input_dim)\n",
    "    decoder_linear_0 = Dense(2*input_shape, name=\"decoder_out\")(flat_0)\n",
    "    return Model(inputs=[decoder_input], outputs=[decoder_linear_0], name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = make_encoder((513, 2), 64)\n",
    "enc.compile()\n",
    "enc.summary()\n",
    "\n",
    "dec = make_decoder((513, 2), 64)\n",
    "dec.compile()\n",
    "dec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim  = (513, 2)\n",
    "latent_dim = 256\n",
    "base_lr    = 4e-4\n",
    "\n",
    "icp_model = GaussianBetaVAE(5, input_dim, latent_dim, make_encoder, make_decoder)\n",
    "\n",
    "opt = optimizers.Adam(lr=base_lr)\n",
    "icp_model.custom_compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "981/981 [==============================] - 73s 51ms/step - ELBO: -36933.8594 - reg: 64.6558 - rec: -36998.5152 - val_ELBO: -36940.5049 - val_reg: 64.0821 - val_rec: -37004.5869\n",
      "Epoch 2/5\n",
      "981/981 [==============================] - 21s 21ms/step - ELBO: -36940.5998 - reg: 64.0650 - rec: -37004.6648 - val_ELBO: -36940.6448 - val_reg: 64.0888 - val_rec: -37004.7336\n",
      "Epoch 3/5\n",
      "981/981 [==============================] - 21s 21ms/step - ELBO: -36940.6966 - reg: 64.0562 - rec: -37004.7528 - val_ELBO: -36940.7081 - val_reg: 64.0177 - val_rec: -37004.7258\n",
      "Epoch 4/5\n",
      "981/981 [==============================] - 21s 22ms/step - ELBO: -36940.7397 - reg: 64.0190 - rec: -37004.7586 - val_ELBO: -36940.7448 - val_reg: 64.0114 - val_rec: -37004.7562\n",
      "Epoch 5/5\n",
      "981/981 [==============================] - 21s 21ms/step - ELBO: -36940.7815 - reg: 64.0065 - rec: -37004.7880 - val_ELBO: -36940.8010 - val_reg: 64.0096 - val_rec: -37004.8106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2cc65f750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icp_model.fit(\n",
    "    x=stft_train,\n",
    "    y=stft_train,\n",
    "    shuffle=True,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=(stft_test, stft_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the latent distribution(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mvn(x_mu, x_logvar):\n",
    "    x_std = np.exp(x_logvar)\n",
    "    batch = x_std.shape[0]\n",
    "    \n",
    "    mvn = tfp.distributions.MultivariateNormalDiag(\n",
    "        loc=x_mu, scale_diag=x_std\n",
    "    )\n",
    "    return mvn.sample(shape=[batch]).numpy()\n",
    "\n",
    "\n",
    "test_stft_frames = stft_frames_scaled.copy() #spectral_audio_dataset[\"Data\"]\n",
    "test_stft_frames = np.reshape(test_stft_frames, newshape=(-1, 173, 1026))\n",
    "print(test_stft_frames.shape)\n",
    "\n",
    "k = np.random.randint(size=1, low=0, high=806)[0]\n",
    "print(k)\n",
    "\n",
    "test_frames = test_stft_frames[k, :, :]\n",
    "print(test_frames.shape)\n",
    "\n",
    "x_mu, x_logvar, _, _ = icp_model.predict(test_frames)\n",
    "\n",
    "pred_stft = sample_mvn(x_mu, x_logvar)\n",
    "pred_stft = scaler.inverse_transform(np.clip(pred_stft, -1, 1))\n",
    "pred_stft = np.reshape(pred_stft, newshape=(513, 173, 2))\n",
    "print(pred_stft.shape)\n",
    "\n",
    "S = np.zeros(pred_stft.shape[:-1], dtype=np.complex)\n",
    "S.real = pred_stft[:, :, 0]\n",
    "S.imag = pred_stft[:, :, 1]\n",
    "M = np.abs(S)\n",
    "M_db = librosa.amplitude_to_db(M)\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(M_db, sr=SR,\n",
    "                               y_axis='log', x_axis='time', ax=ax)\n",
    "\n",
    "y_ = librosa.istft(stft_matrix = S, \n",
    "                   hop_length  = OVERLAP, \n",
    "                   window      = FFTWIN)\n",
    "\n",
    "import IPython.display as ipd\n",
    "ipd.display(ipd.Audio(y_, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "timedur_ms  = 100.\n",
    "timedur_ss  = timedur_ms / 1000.\n",
    "timesteps   = int(np.ceil(timedur_ss * SR / OVERLAP))\n",
    "overlap     = timesteps // 2\n",
    "\n",
    "# Reshape inputs into original \"spectrums\"\n",
    "ORGDIM_TIME = int(np.ceil(DUR * SR / OVERLAP))\n",
    "ORGDIM_FREQ = normalized_power_spectrum.shape[-1]\n",
    "\n",
    "ax0 = (0, 0)\n",
    "ax1 = (timesteps - 1, 0)\n",
    "ax2 = (0, 0)\n",
    "\n",
    "power_spectrum = normalized_power_spectrum.reshape(\n",
    "    (-1, ORGDIM_TIME, ORGDIM_FREQ)\n",
    ")\n",
    "power_spectrum = np.pad(\n",
    "    power_spectrum, [ax0, ax1, ax2], mode='constant'\n",
    ")\n",
    "\n",
    "phase_spectrum = normalized_phase_spectrum.reshape(\n",
    "    (-1, ORGDIM_TIME, ORGDIM_FREQ)\n",
    ")\n",
    "phase_spectrum = np.pad(\n",
    "    phase_spectrum, [ax0, ax1, ax2], mode='constant'\n",
    ")\n",
    "\n",
    "print(power_spectrum.shape, phase_spectrum.shape)\n",
    "\n",
    "p = phase_spectrum.shape[0]\n",
    "q = ORGDIM_TIME\n",
    "r = timesteps\n",
    "j = ORGDIM_FREQ\n",
    "\n",
    "power_spectrum_timesteps = np.zeros((p, q, r, j))\n",
    "phase_spectrum_timesteps = np.zeros((p, q, r, j))\n",
    "\n",
    "def time_slices_for(arr):\n",
    "    niters = ORGDIM_TIME\n",
    "    slices = [arr[:, i:i+timesteps] for i in range(niters)]\n",
    "    return np.array(slices)\n",
    "\n",
    "for ix, spectrums in enumerate(zip(power_spectrum, phase_spectrum)):\n",
    "    stft_arrs = np.array(spectrums)\n",
    "    stft_slices = time_slices_for(stft_arrs)\n",
    "    power_spectrum_timesteps[ix] = stft_slices[:, 0, :, :]\n",
    "    phase_spectrum_timesteps[ix] = stft_slices[:, 1, :, :]\n",
    "\n",
    "power_spectrum_timesteps = power_spectrum_timesteps.reshape((-1, r, j))\n",
    "phase_spectrum_timesteps = phase_spectrum_timesteps.reshape((-1, r, j))\n",
    "print(power_spectrum_timesteps.shape, phase_spectrum_timesteps.shape)\n",
    "\n",
    "#print(194 // (timesteps - 1))    \n",
    "#print(ORGDIM_TIME / (timesteps - overlap))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
